import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from deap import base, creator, tools, algorithms

# Load dataset
data = pd.read_csv('C:/Users/ASUS/Desktop/CMU/Train Multilayer Perceptron/wdbc.data.txt', header=None)
X = data.iloc[:, 2:].values
y = data.iloc[:, 1].values

# Encode class labels
le = LabelEncoder()
y = le.fit_transform(y)

# Standardize features
sc = StandardScaler()
X = sc.fit_transform(X)

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

# Define the MLP model
def create_mlp(hidden_layer_sizes):
    return MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=1000, random_state=42)

# Genetic Algorithm setup
creator.create("FitnessMax", base.Fitness, weights=(1.0,))
creator.create("Individual", list, fitness=creator.FitnessMax)

toolbox = base.Toolbox()
toolbox.register("attr_int", np.random.randint, 5, 100)
toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_int, n=2)
toolbox.register("population", tools.initRepeat, list, toolbox.individual)

def eval_mlp(individual):
    hidden_layer_sizes = tuple(individual)
    mlp = create_mlp(hidden_layer_sizes)
    scores = cross_val_score(mlp, X_train, y_train, cv=10)
    return scores.mean(),

toolbox.register("evaluate", eval_mlp)
toolbox.register("mate", tools.cxTwoPoint)
toolbox.register("mutate", tools.mutUniformInt, low=5, up=100, indpb=0.2)
toolbox.register("select", tools.selTournament, tournsize=3)

# Genetic Algorithm parameters
population = toolbox.population(n=50)
ngen = 40
cxpb = 0.5
mutpb = 0.2

# Run Genetic Algorithm
algorithms.eaSimple(population, toolbox, cxpb, mutpb, ngen, stats=None, halloffame=None, verbose=True)

# Get the best individual
best_individual = tools.selBest(population, k=1)[0]
best_hidden_layer_sizes = tuple(best_individual)

# Train final model with the best hidden layer sizes
final_mlp = create_mlp(best_hidden_layer_sizes)
final_mlp.fit(X_train, y_train)

# Evaluate the model
y_pred = final_mlp.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')
